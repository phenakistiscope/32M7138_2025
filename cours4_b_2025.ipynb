{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b86150d0-9fb9-4ce6-88f6-7f0d8c0a4fea",
   "metadata": {},
   "source": [
    "# L’image dans la machine II\n",
    "\n",
    "## Du pixel aux images - 32M7138\n",
    "\n",
    "*Printemps 2025 - Université de Genève*\n",
    "\n",
    "*Adrien Jeanrenaud (adrien.jeanrenaud@unige.ch)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25791e6d-8334-4f1c-8704-cd16a903c569",
   "metadata": {},
   "source": [
    "## **Plan du cours**\n",
    "\n",
    "> **Appliquer des transformations à une image**\n",
    "> * Modification sur un pixel\n",
    "> * Modification sur plusieurs pixels\n",
    "> * Notions de bruits et de filtres\n",
    "> * Exemple d'application : détecter les contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00e85d4-22ca-4e94-86af-a9e8c4af81b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniquement pour Google Colab\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5279c45c-d66f-475c-a396-231f44884f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d3b5fc-fedf-4322-bf36-2b51f938b7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "# Lien de partage\n",
    "file_id = \"1SKRafrz2xDAoBszxotXA0TkPKRqdycct\"\n",
    "download_url = f\"https://drive.google.com/uc?export=download&id={file_id}\"\n",
    "\n",
    "# Télécharger l'image --> à vous de jouer\n",
    "response = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac5d318-fb92-4eb2-a9f3-49bd362c22fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "chemin_image = \"images/coins.jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385e3269-0b81-4457-a80c-8648c58d6400",
   "metadata": {},
   "source": [
    "### Modification sur un pixel\n",
    "\n",
    "Une image est composée de pixels, chacun ayant une couleur définie par des valeurs (R, V, B) pour le rouge, le vert et le bleu. Modifier un pixel revient à changer ces valeurs.\n",
    "\n",
    "**Exemples d'application**\n",
    "\n",
    "- Changer la couleur d'un pixel (ex: transformer un pixel rouge en bleu).\n",
    "- Appliquer un effet de luminosité en augmentant les valeurs des pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f55b85c-88a5-49b7-8023-e394992ac7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger une image\n",
    "image = cv2.imread(chemin_image)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Modifier un pixel (exemple : changer le pixel en haut à gauche en rouge)\n",
    "image[0,0] = [0, 0, 255]  # Bleu, Vert, Rouge (BGR)\n",
    "\n",
    "plt.imshow(image[0:10,0:10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3341646-4ba2-4f62-9957-8f04d8eb1a1f",
   "metadata": {},
   "source": [
    "### Modification sur plusieurs pixels\n",
    "\n",
    "Modifier plusieurs pixels en même temps permet d'effectuer des traitements globaux comme le changement de contraste, la conversion en noir et blanc, etc.\n",
    "\n",
    "**Exemple d'application**\n",
    "\n",
    "- Convertir une image en noir et blanc.\n",
    "- Augmenter ou diminuer la luminosité de toute l'image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af863b5d-bf46-4e1a-8482-ca17d207329a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger une image\n",
    "image = cv2.imread(chemin_image)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Modifier un pixel (exemple : changer le pixel en haut à gauche en rouge)\n",
    "image[0:500, 0:500] = [0, 0, 255]  # Bleu, Vert, Rouge (BGR)\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ba297f-607d-4fb7-9a26-66ff5d23be4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion en niveaux de gris\n",
    "image = cv2.imread(chemin_image)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "plt.imshow(gray, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6713989e-a52c-4edd-9877-afd399a8d7aa",
   "metadata": {},
   "source": [
    "#### Exposition et contraste\n",
    "\n",
    "L'exposition\n",
    "\n",
    "Il est possible de corriger l'exposition, c'est à dire d'éclaircir ou d'assombrir une image. En utilisant le correction gamma, on contrôle la luminosité en changeant les ratios RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab047c0-e531-47d1-b840-5ecbbcbd8348",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import exposure\n",
    "\n",
    "?exposure.adjust_gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c355921d-c784-4b58-a02f-466564968b36",
   "metadata": {},
   "source": [
    "**En dessous de 1, l'image s'éclaircit, en dessus de 1 elle s'assombrit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938cff97-7da8-4e98-bcfc-24a40267f3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image couleur\n",
    "color_gamma = exposure.adjust_gamma(image, gamma = 2.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a093b801-90b1-4c25-80d3-5b5e689ca410",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize = (20,10))\n",
    "                                                 \n",
    "ax1.set_title ('Image en couleurs')\n",
    "ax1.imshow(image)\n",
    "\n",
    "ax2.set_title ('Image transformée')\n",
    "ax2.imshow(color_gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f550fdf-fbf2-4585-9dfd-70f3f2c5fc0a",
   "metadata": {},
   "source": [
    "**Le contraste**\n",
    "\n",
    "Le contraste définit la répartition de lumière dans l'image.\n",
    "Modifier le contraste de l'image permet d'ouvrir la fenêtre des pixels ; si les valeurs min et max ont peu d'écart, il est possible d'augmenter la rangée des valeurs utilisées\n",
    "\n",
    "Mofifier le contraste à la main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363fd371-29fa-41b7-a85d-681cd6835750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trouver les valeurs min et max \n",
    "\n",
    "ma = gray.max()\n",
    "mi = gray.min()\n",
    "print(mi,ma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db289f1e-b96d-4903-a3a8-88d82153d492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir l'image en float et ouvrir la fenêtre de valeurs\n",
    "\n",
    "c = gray.astype(float)\n",
    "gray_c = 255.0*(c-mi)/(ma-mi+0.0000001).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec756d2-0c3f-4ca9-bb65-85f70622e3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Est-ce que ça a bien fonctionné ?\n",
    "\n",
    "ma1 = gray_c.max()\n",
    "mi1 = gray_c.min()\n",
    "print(mi1,ma1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ba1109-94e1-452d-a729-3da6f677ed1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Est-ce que ça a bien fonctionné ?\n",
    "\n",
    "ma1 = gray_c.max()\n",
    "mi1 = gray_c.min()\n",
    "print(mi1,ma1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f418a0-4ab2-4b8f-8158-937e109d170b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize = (20,10))\n",
    "                                                 \n",
    "ax1.set_title ('Image en valeurs de gris')\n",
    "ax1.imshow(gray,cmap = \"gray\")\n",
    "\n",
    "ax2.set_title ('Image transformée')\n",
    "ax2.imshow(gray_c,cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6a4275-34ee-402c-95bb-05986071f635",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6562827d-9721-40e0-95e6-c1cb86f007ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On divise l'image en différents r, g, b \n",
    "\n",
    "r,g,b = cv2.split(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5014aa-4421-45e4-91c5-5e62982cbdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ma = r.max()\n",
    "mi = r.min()\n",
    "print(mi,ma)\n",
    "c = r.astype(float)\n",
    "im1r = 255.0*(c-mi)/(ma-mi+0.0000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94d4c49-34bd-4ccd-b4e9-5d91de5c3691",
   "metadata": {},
   "outputs": [],
   "source": [
    "ma = g.max()\n",
    "mi = g.min()\n",
    "print(mi,ma)\n",
    "c = g.astype(float)\n",
    "im1g = 255.0*(c-mi)/(ma-mi+0.0000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9945fddc-de6e-48ec-b359-0bc774a29995",
   "metadata": {},
   "outputs": [],
   "source": [
    "ma = b.max()\n",
    "mi = b.min()\n",
    "print(mi,ma)\n",
    "c = b.astype(float)\n",
    "im1b = 255.0*(c-mi)/(ma-mi+0.0000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c73be5-09e1-42b9-9bb8-d8f2be6fdb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On remet les canaux ensemble\n",
    "# Attention à l'ordre des canaux de couleurs\n",
    "\n",
    "color_c = cv2.merge([im1r, im1g, im1b]).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65321634-1483-4659-b4cc-b807395acb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize = (20,10))\n",
    "                                                 \n",
    "ax1.set_title ('Image couleur')\n",
    "ax1.imshow(image)\n",
    "\n",
    "ax2.set_title ('Image transformée')\n",
    "ax2.imshow(color_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fae67d3-967a-4a33-9ab0-ec0a6edc6f36",
   "metadata": {},
   "source": [
    "**Seuillage**\n",
    "\n",
    "Le principe du seuillage (threshold) est de passser d'une image en valeurs de gris à une image (ou une partie de l'image) binaire. Une image binaire signifie que chaque pixel n'a que deux choix pour valeur, le plus souvent noir ou blanc. Le seuillage sert à mettre à jour une partie de l'image, un objet en particulier ou des particularités de l'image. Pour pouvoir appliquer un seuillage à une image, il faut nécessairement choisir un seuil, voire deux, qui diviseront la répartition des pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a9c389-d8e9-4637-8fbf-d498a39e2c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "?cv2.threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee251aa-dd37-47df-ac8f-9703d15ee5d9",
   "metadata": {},
   "source": [
    "**Il existe différentes manières de faire du seuillage**\n",
    "\n",
    "* cv2.THRESH_BINARY\n",
    "* cv2.THRESH_BINARY_INV\n",
    "* cv2.THRESH_TRUNC\n",
    "* cv2.THRESH_TOZERO\n",
    "* cv2.THRESH_TOZERO_INV\n",
    "\n",
    "<img src=\"https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fwww.scaler.com%2Ftopics%2Fimages%2Fcv2-threshold-1.webp&f=1&nofb=1&ipt=72602e1a26cdda7b6a27d0fc604c13cf5ba92c1225511443d65b3c20b6953337&ipo=images\" title=\"binary\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ed6613-1f85-45b6-b80d-6389dbf36627",
   "metadata": {},
   "source": [
    "**cv2.THRESH_BINARY**\n",
    "\n",
    "Cette binarisation est la plus simple. Un seuil détermine les valeurs qui seront mises à 0 ou à 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4024d4b-b8d2-4c60-9ff3-f4a82c03eaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La fonction prend comme argument: une image, un seuil, une valeur maximale et un type de seuillage\n",
    "# La fonction retourne: le seuil et l'image binarisée\n",
    "\n",
    "_, gray_b = cv2.threshold(gray, 30, 255, cv2.THRESH_BINARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d08d91d-5d31-4b97-8df5-78303a492660",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"seuil :\", _)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc6c5f6-2b87-450f-a3c9-050696b8afe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les images \n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(211)\n",
    "plt.title(\"Image de base\")\n",
    "plt.imshow(gray, cmap=\"gray\")\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title(\"binary\")\n",
    "plt.imshow(gray_b, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebec031-5712-4dad-b6d4-ac3ef6eb7941",
   "metadata": {},
   "source": [
    "**cv2.THRESH_BINARY_INV**\n",
    "\n",
    "Cette binarisation est l'inverse de la précédente. Si la le pixel est supérieur au seuil, alors la valeur malximale lui sera assigné"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465567e6-7660-40a5-bf7c-0d773f4ded3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La fonction prend comme argument: une image, un seuil, une valeur maximale et un type de seuillage\n",
    "# La fonction retourne: le seuil et l'image binarisée\n",
    "\n",
    "_, gray_bi = cv2.threshold(gray, 30, 255, cv2.THRESH_BINARY_INV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43a5f39-896a-49d2-bfd5-bedcfc4af909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les images \n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(211)\n",
    "plt.title(\"Image de base\")\n",
    "plt.imshow(gray, cmap=\"gray\")\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title(\"binary_inv\")\n",
    "plt.imshow(gray_bi, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502fe2bc-368b-4926-98a2-0812e5acc946",
   "metadata": {},
   "source": [
    "**cv2.THRESH_THRESH_TRUNC**\n",
    "\n",
    "Ce seuillage permet, par le choix d'un seuil T, de transformer tous les pixels supérieurs à la valeur du seuil tandis que les pixels en dessous du seuil ne sont pas modifiés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066bc6a1-ccc3-471b-bdc1-c7efe96e6e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La fonction prend comme argument: une image, un seuil, une valeur maximale et un type de seuillage\n",
    "# La fonction retourne: le seuil et l'image binarisée\n",
    "\n",
    "_, gray_t = cv2.threshold(gray, 100, 255, cv2.THRESH_TRUNC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b15b84a-975d-405b-a112-d6c26e6ce4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les images \n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(211)\n",
    "plt.title(\"Image de base\")\n",
    "plt.imshow(gray, cmap=\"gray\")\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title(\"trunc\")\n",
    "plt.imshow(gray_t, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedd5746-a0fd-4c7a-8ab6-e0203968bce4",
   "metadata": {},
   "source": [
    "**cv2THRESH_TOZERO**\n",
    "\n",
    "Ici il s'agit de définir un seuil dont les valeurs, si elles sont inférieures au seuil, sont mises à 0 tandis que les valeurs supérieures au seuil ne changent pas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850bba7d-a54c-4018-b4bb-5638c49ed6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La fonction prend comme argument: une image, un seuil, une valeur maximale et un type de binarisation\n",
    "# La fonction retourne: le seuil et l'image binarisée\n",
    "\n",
    "_, gray_z = cv2.threshold(gray, 120, 255, cv2.THRESH_TOZERO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df32cb05-9961-41bc-a257-72db7c754fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les images \n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(211)\n",
    "plt.title(\"Image de base\")\n",
    "plt.imshow(gray, cmap=\"gray\")\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title(\"tozero\")\n",
    "plt.imshow(gray_z, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cd3b27-6b74-40d9-a08f-c3c07f124baf",
   "metadata": {},
   "source": [
    "**cv2.THRESH_TOZERO_INV**\n",
    "\n",
    "Cette méthode est similaire à la précédente, à la seule différence que les valeurs en dessus du seuil sont cette fois mises à 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbf99a1-c094-4d29-8688-894cdbdbbcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La fonction prend comme argument: une image, un seuil, une valeur maximale et un type de binarisation\n",
    "# La fonction retourne: le seuil et l'image binarisée\n",
    "\n",
    "_, gray_zi = cv2.threshold(gray, 30, 255, cv2.THRESH_TOZERO_INV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ec9fd7-abff-4715-b2ac-9c8298859a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les images \n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(211)\n",
    "plt.title(\"Image de base\")\n",
    "plt.imshow(gray, cmap=\"gray\")\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title(\"binary\")\n",
    "plt.imshow(gray_zi, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dea545-2a55-4a32-89bd-786b50640b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Thresholding\n",
    "# 0, binary\n",
    "# 1, binary inverted\n",
    "# 2, Truncated\n",
    "# 3, Threshold to Zero\n",
    "# 4, Threshold to Zero inverted\n",
    "\n",
    "_, gray0 = cv2.threshold(gray, 50, 255, 0)\n",
    "_, gray1 = cv2.threshold(gray, 50, 255, 1)\n",
    "_, gray2 = cv2.threshold(gray, 50, 255, 2)\n",
    "_, gray3 = cv2.threshold(gray, 50, 255, 3)\n",
    "_, gray4 = cv2.threshold(gray, 50, 255, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06de466-e0a3-4575-9965-671849b586fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [\"original\", 'BINARY','BINARY_INV','TRUNC','TOZERO','TOZERO_INV']\n",
    "images = [gray, gray0, gray1, gray2, gray3, gray4,]\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.imshow(images[i],cmap=\"gray\")\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3891155a-1406-41d8-b7ee-1cf5793b2ddb",
   "metadata": {},
   "source": [
    "### Notions de bruits et de filtres\n",
    "\n",
    "Le bruit est une altération aléatoire qui peut rendre une image floue ou déformée (ex: bruit de caméra, compression d’image). On utilise des filtres pour atténuer ces bruits.\n",
    "\n",
    "**Exemple d'application**\n",
    "\n",
    "- Réduction du bruit dans des images médicales.\n",
    "- Amélioration de la qualité d’une image prise dans de mauvaises conditions.\n",
    "\n",
    "#### Qu'est-ce qu'un filtre? ?\n",
    "\n",
    "Dans le traitement numérique des images, les filtres sont utilisés principalement pour flouter, améliorer la netteté ou détecter les contours d'une image. Le filtre permet de supprimer les impurtées, le plus souvent il prépare l'image en vue d'opérations plus poussées, comme pour l'apprentissage profond. \n",
    "\n",
    "Un filtre est une petite matrice de dimension impair (3x3, 9x9, etc.) qui s'applique par convolution à l'image. Une convolution est simplement un opération matriciel entre le filtre et l'image. Le filtre (une matrice de 3x3 par exemple), se déplace sur l'image et une nouvelle image est obtenue lorsque l'opération est effectuée sur chaque pixel.\n",
    "L'opération de convolution réduit la taille de l'image, à moins que des bords soient ajoutés. \n",
    "\n",
    "<img src=\"https://miro.medium.com/v2/0*YfpMfPnz6n2g4vIz.jpg\" title=\"filtre\"/>\n",
    "\n",
    "<img src=\"https://drek4537l1klr.cloudfront.net/elgendy/Figures/3-13.png\" title=\"filtre2\"/>\n",
    "\n",
    "#### Attention aux bords\n",
    "\n",
    "Le déplacement du filtre sur l'image pose la question du traitement des bords, car les pixels aux extrémités de l'image doivent avoir le même traitement que les autres ; c'est-à-dire qu'ils doivent passer par toutes les composantes du filtre. Dans ce cas, il y a plusieurs méthodes pour élargir les bords de l'image afin que tous les pixels de l'image de base soient traités correctement. \n",
    "\n",
    "Le processus de création de données en dehors de l'image s'appelle en anglais \"padding\".\n",
    "\n",
    "<img src=\"https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fmiro.medium.com%2Fmax%2F3232%2F1*9reDuDh3nXs_kJ-M4eq0Ow.png&f=1&nofb=1&ipt=5e8431d61861a6afe5ece799945d9a7a3841a1e80ad8eb42c80e8c5b4f567755&ipo=images\" title=\"padding\"/>\n",
    "\n",
    "\n",
    "**Principalement, il y a**\n",
    "> * ajout de zéros\n",
    "> * constante arbitraire\n",
    "> * plus proche voisin\n",
    "> * en miroir \n",
    "> * reprend le bors opposé\n",
    "\n",
    "#### Du filtre à l'image\n",
    "\n",
    "Il existe plusieurs types de filtres dont le paramétrage et les effets sont bien connus. Avant de les aborder, regardons comment l'on peut simplement créer et appliquer un fitlre sur notre image.\n",
    "\n",
    "https://setosa.io/ev/image-kernels/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386f95b4-af3e-4028-a372-fda6907fd9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La fonction convolve de la librairie Scipy nous permet d'opérer une convolution sur une image \n",
    "# Regardons ses paramètres\n",
    "\n",
    "import scipy.ndimage\n",
    "\n",
    "?scipy.ndimage.filters.convolve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e37008b-e2a0-4ec1-85b9-6b88870c2714",
   "metadata": {},
   "source": [
    "**Il nous faut principalement une image (input), un filtre (weights) et un choix de padding (mode)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd18884b-0dfa-4767-80e1-e9fb75778b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un filtre, 3x3 par exemple\n",
    "\n",
    "filtre = np.array([[1,0,1],\n",
    "                  [0,1,0],\n",
    "                  [1,0,1]])\n",
    "print(filtre.shape, \"\\n\", filtre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d8cf98-ac60-4e05-9653-21424c409f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramétrer la convolution\n",
    "\n",
    "grayf = gray.copy()\n",
    "\n",
    "gray_filtre = scipy.ndimage.filters.convolve(grayf, filtre, mode=\"reflect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037ba9f5-971e-423d-bc53-a5f968401e0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05b3857-b0a6-475e-86d4-abc05beb061d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efea8b1d-5113-43cb-8ef2-9efa94608e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize = (20,10))\n",
    "                                                 \n",
    "ax1.set_title ('Image en valeurs de gris')\n",
    "ax1.imshow(gray,cmap = \"gray\")\n",
    "\n",
    "ax2.set_title ('Image transformée')\n",
    "ax2.imshow(gray_filtre,cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57735554-b727-4633-8f05-fbeab4023815",
   "metadata": {},
   "source": [
    "#### Des filtres pour réduire le bruit\n",
    "\n",
    "Il existe plusieurs filtres bien connus dont:\n",
    "\n",
    "##### Filtre médian\n",
    "\n",
    "Le filtre médian permet de réduire le bruit tout en conservant les contours, il est souvent utilisé pour supprimer le bruit sel et poivre (incursion de pixels noirs et blancs dans l'image) ; chaque pixel est remplacé par la médiane de son voisinage et cela permet de supprimer les valeurs abberantes. Le filtre médian garde le contraste, la luminosité et les contours\n",
    "\n",
    "<img src=\"https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fi.stack.imgur.com%2Fdw60I.png&f=1&nofb=1&ipt=98a04cc296528ada2699bafee8ef3eafe1af5ab35f7a2d6743a7659fdbe48dc8&ipo=images\" title=\"median\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b9f6e5-f188-4e1e-a19e-d5cd448bec8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667d158e-4165-4f30-954e-98e5aa16210a",
   "metadata": {},
   "outputs": [],
   "source": [
    "?scipy.ndimage.filters.median_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aeb99a3-fdda-4d7e-b624-18ba7423c950",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90d259f-9af8-4703-9172-af48f51766d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "DownURL = \"https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fi.stack.imgur.com%2FJ13Wn.jpg&f=1&nofb=1&ipt=941e7a6b4eee937a7348d2cc6752d0572048342830b97d90f7545151c03dcee3&ipo=images\" # choix de l'URL\n",
    "img_data = requests.get(DownURL).content # télécharger\n",
    "with open('noise.jpg', 'wb') as handler: # définir le fichier et son chemin\n",
    "    handler.write(img_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2ee166-0ce2-4eaa-9fa7-c7f933a97fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramétrage de la fonction\n",
    "# La fonction prend principalement en paramètres une image (input), la taille du filtre (size) et le type de padding (mode)\n",
    "\n",
    "path = \"noise.jpg\"\n",
    "image = cv2.imread(path)\n",
    "gray_mm = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "gray_median = scipy.ndimage.filters.median_filter(gray_mm, size=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1720a665-50fa-404b-bd5f-174c0aee7216",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize = (20,10))\n",
    "                                                 \n",
    "ax1.set_title ('Image en valeurs de gris')\n",
    "ax1.imshow(gray_mm,cmap = \"gray\")\n",
    "\n",
    "ax2.set_title ('Image transformée')\n",
    "ax2.imshow(gray_median,cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b200b1-394f-415a-88c8-292a25b9dd6c",
   "metadata": {},
   "source": [
    "#### Filtre Gaussien\n",
    "\n",
    "Le filtre gaussien, comme son nom l'indique suit une distribution gaussienne, c'est-à-dire une loi normale centrée et réduite. Le sigma définit la forme de la cloche, et dans le traitement de l'image cela signifie que le bruit peut être réduit (sigma < 1) ou que le flou peut être accentué (sigma > 1).\n",
    "\n",
    "Le filtre gaussien vient lisser les imperfection de l'image, les détails et les contours sont atténués.\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/1/10/Generalized_normal_densities.svg/langfr-560px-Generalized_normal_densities.svg.png\" title=\"gauss\"/>\n",
    "\n",
    "<img src=\"https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Ftse1.mm.bing.net%2Fth%3Fid%3DOIP.JpX8ONYKxZmIBAHIi1KpjAHaIy%26pid%3DApi&f=1&ipt=f751c30b941d608cdf6715c0829c2abc7c2d6f08aa83e0155fe4bef8ebc48ea9&ipo=images\" title=\"gauss2\"/>\n",
    "\n",
    "<img src=\"https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fsupport.cognex.com%2Fdocs%2Fcvl_900%2Fweb%2FEN%2Fcvl_vision_tools%2FContent%2FImages%2F18_8.jpg&f=1&nofb=1&ipt=0ba811ae846f092e40b20e9c7f1d74fc7f1e0f88240a48ec1ce7483ca4f1017b&ipo=images\" title=\"gauss3\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cad6b4-c92e-41e5-9ea3-41ad1049bf2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8485a62c-2132-4a77-8e20-7ec91c52398a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a8d85c-2c68-4143-b82d-b1580a3aa50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "?scipy.ndimage.filters.gaussian_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481778bd-ddcd-4775-81d3-ef77b42e1a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramétrage de la fonction\n",
    "# La fonction prend principalement une image (input) et un sigma\n",
    "\n",
    "gray_g = gray_mm.copy()\n",
    "\n",
    "gray_gauss = scipy.ndimage.filters.gaussian_filter(gray_g, sigma=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fb6104-6450-40b3-a23d-2046e5255395",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize = (20,10))\n",
    "                                                 \n",
    "ax1.set_title ('Image en valeurs de gris')\n",
    "ax1.imshow(gray_mm,cmap = \"gray\")\n",
    "\n",
    "ax2.set_title ('Image transformée')\n",
    "ax2.imshow(gray_gauss,cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffe2b64-c652-4ac0-8258-9e846f6318a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae5af5a-fc8c-491a-9e6b-49537c547da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Il existe également une fonction similaire dans la librairie OpenCV\n",
    "\n",
    "?cv2.GaussianBlur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab88fc1-0c3d-49f7-925b-c0865b956d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramétrage de la fonction\n",
    "# La fonction prend principalement une image, une taille de filtre (ksize) et un sigma\n",
    "\n",
    "gray_gcv = gray_mm.copy()\n",
    "\n",
    "gray_gausscv = cv2.GaussianBlur(gray_gcv, (9,9), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a967a82f-5ac4-4bf2-85c7-b15041a97a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize = (20,10))\n",
    "                                                 \n",
    "ax1.set_title ('Image en valeurs de gris')\n",
    "ax1.imshow(gray_mm,cmap = \"gray\")\n",
    "\n",
    "ax2.set_title ('Image transformée')\n",
    "ax2.imshow(gray_gausscv,cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e9da18-8c6d-4150-a360-52b63ff60b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7305de81-7a85-4760-9d09-6b0e9a9af20d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Exercice</b>: à partir de l'image et de la détection des visages ci-dessous, il vous faudra flouter ces visages et enregistrer l'image.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae4a895-cb58-488e-b0a9-205615b4243d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf9f6f2-fee5-441c-ba3a-a44f168d9bbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad58d85-48a1-48d1-93bf-66d13444cc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# télécharger une image\n",
    "\n",
    "import requests \n",
    "\n",
    "DownURL = \"https://external-content.duckduckgo.com/iu/?u=http%3A%2F%2Fwww.bluebird-electric.net%2Facademia%2Facademia_pictures%2FUniversity_of_Geneva_Universite_de_Geneve_Switzerland_Planet_Solar.jpg&f=1&nofb=1&ipt=47cb55e9bf396b35de8f272546914dbe02979fdd2163fd7e2e15601bec35314c&ipo=images\" # choix de l'URL\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35adaf99-2c20-4d22-91fa-d60639ff602f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import notre image\n",
    "\n",
    "path = \"unige.jpg\"\n",
    "image = cv2.imread(path)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbce6d11-39df-4da5-b8b4-d95ae34d6419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appliquer un algorithme simple\n",
    "# https://towardsdatascience.com/viola-jones-algorithm-and-haar-cascade-classifier-ee3bfb19f7d8\n",
    "\n",
    "grayscale_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_alt.xml\") #https://github.com/opencv/opencv/tree/master/data/haarcascades\n",
    "detected_faces = face_cascade.detectMultiScale(grayscale_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19112935-5fc2-46e1-8d66-642c65d6fed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flouter les visages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2687177a-537a-4603-a3a7-89b23af83808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dessiner les lignes\n",
    "\n",
    "for (column, row, width, height) in detected_faces:\n",
    "    image = cv2.rectangle(image,(column, row),(column + width, row + height),(0, 255, 0),4)\n",
    "plt.imshow(image)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11a0037-57bc-4250-8e04-041711f51296",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a4bc531-a245-4c03-a6af-e78cb3623413",
   "metadata": {},
   "source": [
    "### Exemple d'application : détecter les contours\n",
    "\n",
    "Dans une image, un contour se comprend comme la différence d'intensité entre deux pixels. La détection de contours cherche le changement soudain entre deux valeurs de pixel.\n",
    "\n",
    "Mathématiquement le calcul d'intensité se fait par l'utilisation de dérivées : en somme, l'application de une ou deux dérivées permet d'accentuer le contraste entre deux parties de l'image sensées décrire un contour. \n",
    "\n",
    "<img src=\"https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Ftse2.mm.bing.net%2Fth%3Fid%3DOIP.jeER_gFbhKiY_iGIJrGmjAHaDd%26pid%3DApi&f=1&ipt=1495f4b2280deda1acd3572573157b7525409b810d4a084765dc7d298013d016&ipo=images\" title=\"edge\"/>\n",
    "\n",
    "Il existe plusieurs types de filtres bien connus pour la détection des contours, nous allons en voir certains:\n",
    "\n",
    "* Prewitt\n",
    "* Sobel\n",
    "* Canny\n",
    "* Laplacien\n",
    "* Laplacien Gaussien\n",
    "\n",
    "\n",
    "#### Filtre Canny\n",
    "\n",
    "Le filtre Canny permet de détecter les contours (sans division horizontale et verticale préalable, comme le Sobel et Prewitt). Il est performant dans la détection (contours faibles et forts) et dans la localisation des contours (faible erreur entre contours détectés et contours réels). Malgré sa performance, son coup d'utilisation est non néglibeable.\n",
    "\n",
    "En d'autres termes, voilà le processus simplifié du filtre Canny:\n",
    "\n",
    "<img src=\"https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fimage.slidesharecdn.com%2Fe2822eef-6993-4540-9321-65ca5f35eb39-161009120200%2F95%2Fexploring-methods-to-improve-edge-detection-with-canny-algorithm-13-638.jpg%3Fcb%3D1476014597&f=1&nofb=1&ipt=f300f199eaf34361e890d50c9054e9b38c9b25b29d6863942c7ec716bbdbc49b&ipo=images\" title=\"k-means2\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fbe7a2-4321-41e7-a20b-734b5cc440e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "?cv2.Canny"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30aeac45-f52f-49ef-980e-b4363d937a32",
   "metadata": {},
   "source": [
    "**La fonction prend principalement comme arguments: une image, un seuil bas et un seuil haut**\n",
    "\n",
    "> * En dessous du seuil bas, le pixel est rejeté\n",
    "> * En dessus du seuil haut, le pixel est considéré comme un contour\n",
    "> * Entre, si le pixel est connecté au seuil haut, il est accepté"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffb8093-5ae4-4bb4-b151-ee265eaea339",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801fc3d7-8505-4668-98ea-30f3aa41d732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramétrage de la fonction\n",
    "\n",
    "gray_c = gray.copy()\n",
    "\n",
    "gray_canny = cv2.Canny(gray_c, 100, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d199f5-bbb2-4aad-8e22-9579fd0ca5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize = (20,10))\n",
    "                                                 \n",
    "ax1.set_title ('Image en valeurs de gris')\n",
    "ax1.imshow(gray,cmap = \"gray\")\n",
    "\n",
    "ax2.set_title ('Image transformée')\n",
    "ax2.imshow(gray_canny,cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca32a390-00d2-46b9-bd76-533147462275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramétrage de la fonction\n",
    "\n",
    "gray_c = gray_mm.copy()\n",
    "\n",
    "gray_canny = cv2.Canny(gray_c, 100, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383d41bd-4515-4442-a9d9-f4c93994f555",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize = (20,10))\n",
    "                                                 \n",
    "ax1.set_title ('Image en valeurs de gris')\n",
    "ax1.imshow(gray_mm,cmap = \"gray\")\n",
    "\n",
    "ax2.set_title ('Image transformée')\n",
    "ax2.imshow(gray_canny,cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dd35fb-2b72-4d60-b4b7-356a973f9462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajoutons un filtre median en amont\n",
    "\n",
    "gray_c = gray_mm.copy()\n",
    "\n",
    "gray_median = scipy.ndimage.filters.median_filter(gray_mm, size=9)\n",
    "gray_canny = cv2.Canny(gray_median, 100, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050e46f4-6f32-4bae-a281-ac965df7629a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize = (20,10))\n",
    "                                                 \n",
    "ax1.set_title ('Image en valeurs de gris')\n",
    "ax1.imshow(gray_mm,cmap = \"gray\")\n",
    "\n",
    "ax2.set_title ('Image transformée')\n",
    "ax2.imshow(gray_canny,cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72453484-8377-4a24-a3de-2023e2286b15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3616e1-ffe4-4e88-880b-74fc47aed96f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
